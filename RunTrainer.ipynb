{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2221e7-1c0b-4f35-a498-621536457152",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Step 1: Import Modules\n",
    "from DataLoader import ADE20KDownloader\n",
    "from DataHandler import DataHandler \n",
    "from DeepLabV3Plus import DeepLabV3Plus  # The DeepLabV3+ model implementation\n",
    "from Trainer import Trainer  # The Trainer class to handle the training process\n",
    "from DisplayCallback import DisplayCallback  # The display callback for visualization\n",
    "from ModelEvaluator import ModelEvaluator\n",
    "\n",
    "IMG_SIZE = 256 # Replace with your image size\n",
    "N_CLASSES = 21  # Replace with the number of classes in your dataset\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATASET_PATH = 'ADEChallengeData2016/images'\n",
    "DOWNLOAD_PATH = 'path_to_download'\n",
    "DOWNLOAD_PATH = os.path.join(BASE_DIR, DOWNLOAD_PATH)\n",
    "DATASET_PATH = os.path.join(DOWNLOAD_PATH, DATASET_PATH)\n",
    "downloader = ADE20KDownloader(DOWNLOAD_PATH)\n",
    "downloader.download_ade(overwrite=False)  # Overwrite existing files if set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba7cab9f-df86-4906-9db2-f4e72c619ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    " \n",
    "training_data = \"training/\"\n",
    "val_data = \"validation/\"\n",
    "SEED = 42\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "TRAINSET_SIZE = len(glob( os.path.join(DATASET_PATH,training_data) + \"*.jpg\"))\n",
    "print(f\"The Training Dataset contains {TRAINSET_SIZE} images.\")\n",
    "\n",
    "VALSET_SIZE = len(glob(os.path.join(DATASET_PATH,val_data)+ \"*.jpg\"))\n",
    "print(f\"The Validation Dataset contains {VALSET_SIZE} images.\")\n",
    "\n",
    "\n",
    "def parse_image(img_path: str) -> dict:\n",
    "    \"\"\"Load an image and its annotation (mask) and returning\n",
    "    a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_path : str\n",
    "        Image (not the mask) location.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping an image and its annotation.\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "    # For one Image path:\n",
    "    # .../trainset/images/training/ADE_train_00000001.jpg\n",
    "    # Its corresponding annotation path is:\n",
    "    # .../trainset/annotations/training/ADE_train_00000001.png\n",
    "    mask_path = tf.strings.regex_replace(img_path, \"images\", \"annotations\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"jpg\", \"png\")\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    # The masks contain a class index for each pixels\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    # In scene parsing, \"not labeled\" = 255\n",
    "    # But it will mess up with our N_CLASS = 150\n",
    "    # Since 255 means the 255th class\n",
    "    # Which doesn't exist\n",
    "    mask = tf.where(mask == 255, np.dtype('uint8').type(0), mask)\n",
    "    # Note that we have to convert the new value (0)\n",
    "    # With the same dtype than the tensor itself\n",
    "\n",
    "    return {'image': image, 'segmentation_mask': mask}\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.list_files( os.path.join(DATASET_PATH, training_data) + \"*.jpg\", seed=SEED)\n",
    "train_dataset = train_dataset.map(parse_image)\n",
    "\n",
    "val_dataset = tf.data.Dataset.list_files(os.path.join(DATASET_PATH, val_data) + \"*.jpg\", seed=SEED)\n",
    "val_dataset =val_dataset.map(parse_image)\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def create_ade20k_label_colormap(file_path):\n",
    "    \"\"\"Creates a label colormap used in ADE20K segmentation benchmark from a file.\n",
    "\n",
    "    Args:\n",
    "      file_path: The path to the CSV file containing the colormap.\n",
    "\n",
    "    Returns:\n",
    "      A colormap for visualizing segmentation results.\n",
    "    \"\"\"\n",
    "    colormap = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            colormap.append([int(c) for c in row])\n",
    "\n",
    "    return np.asarray(colormap)\n",
    "\n",
    "# Example usage:\n",
    "# Make sure to have a file 'ade20k_colormap.csv' with the color values.\n",
    "file_path = 'ade20k_colormap.csv'\n",
    "ade20k_colormap = create_ade20k_label_colormap(file_path)\n",
    "\n",
    "with open(\"objectInfo151.txt\", \"r\") as file:\n",
    "    lines = file.readlines()[1:152]\n",
    "\n",
    "class_names = []\n",
    "pixel_count_dict = {}\n",
    "color_dict = {}  # This dictionary will store the color for each class\n",
    "for idx, line in enumerate(lines):\n",
    "    parts = line.split('\\t')\n",
    "    class_idx = int(parts[0])\n",
    "    class_name = parts[4].strip()\n",
    "    class_names.append(class_name)\n",
    "\n",
    "     \n",
    "    color_dict[class_name] = ade20k_colormap[idx]\n",
    "  \n",
    "N_TOTAL_CLASSES = len(class_names)\n",
    " \n",
    "CLASSES_COLOR_DICT = color_dict  \n",
    "#name_to_index_dict = {name: index for index, name in enumerate(class_names)}\n",
    "name_to_index_dict = {name: index for index, name in enumerate(class_names, start=0)}\n",
    " \n",
    " \n",
    "@tf.function\n",
    "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
    "     \n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(datapoint: dict) -> tuple:\n",
    "     \n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask) \n",
    "        \n",
    "    input_image = tf.image.random_brightness(input_image, max_delta=0.3)  \n",
    "    input_image = tf.image.random_contrast(input_image, lower=0.8, upper=1.2)   \n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def load_image_test(datapoint: dict) -> tuple:\n",
    "   \n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "def filter_label(image, label):\n",
    "    label = tf.where(tf.equal(label, N_TOTAL_CLASSES), tf.cast(tf.constant(0), label.dtype), label)  \n",
    "    return image, label\n",
    "\n",
    " \n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = {\"train\": train_dataset, \"val\": val_dataset}\n",
    "\n",
    "# -- Train Dataset --#\n",
    "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset['train'] = dataset['train'].map(filter_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)   \n",
    "dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
    "#dataset['train'] = dataset['train'].repeat()\n",
    "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
    "dataset['train'] = dataset['train'].prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "#-- Validation Dataset --#\n",
    "dataset['val'] = dataset['val'].map(load_image_test)\n",
    "dataset['val'] = dataset['val'].map(filter_label)  # 추가\n",
    "#dataset['val'] = dataset['val'].repeat()\n",
    "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
    "dataset['val'] = dataset['val'].prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ffad65-9de9-47df-93c9-f36926bb1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to create and train a model...\n",
    "# model = create_model()\n",
    "# train_model(model, train_dataset, val_dataset)\n",
    "\n",
    "# Step 3: Initialize the Model\n",
    "# Set the image size and the number of classes based on your dataset\n",
    "\n",
    "deeplab = DeepLabV3Plus(image_size=IMG_SIZE, num_classes=N_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f09eeca-1cdb-4632-86ab-03371d1853c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume train_images, train_masks, val_images, val_masks are already prepared.\n",
    "  \n",
    "trainer = Trainer(model=deeplab.model, dataset=dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Step 5: Start Training\n",
    "model_history = trainer.train()\n",
    "\n",
    "# Optionally, visualize the results after training\n",
    "# Visualization would depend on what your 'show_predictions()' function does\n",
    "# For example, if you have a test image and mask, you could do:\n",
    "# test_img, test_mask = data_loader.get_test_sample()  # Assuming this method exists\n",
    "# predicted_mask = model.predict(test_img)\n",
    "# display_segmentation(test_img, test_mask, predicted_mask)  # Assuming this function exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5549bb21-a84c-410d-b50b-5449dc171cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_evaluator = ModelEvaluator(deeplab.model, dataset, name_to_index_dict, CLASSES_COLOR_DICT)\n",
    "model_evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461e4b2-b781-412c-a6c1-ff6cc913e216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31bb42-9914-46b5-8c77-2539c53725bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
