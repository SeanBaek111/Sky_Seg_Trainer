{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f2221e7-1c0b-4f35-a498-621536457152",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/v-newtf/lib/python3.9/site-packages/tensorflow_addons/utils/tfa_eol_msg.py:23: UserWarning: \n",
      "\n",
      "TensorFlow Addons (TFA) has ended development and introduction of new features.\n",
      "TFA has entered a minimal maintenance and release mode until a planned end of life in May 2024.\n",
      "Please modify downstream libraries to take dependencies from other repositories in our TensorFlow community (e.g. Keras, Keras-CV, and Keras-NLP). \n",
      "\n",
      "For more information see: https://github.com/tensorflow/addons/issues/2807 \n",
      "\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Step 1: Import Modules\n",
    "from DataLoader import ADE20KDownloader\n",
    "from DataHandler import DataHandler \n",
    "from DeepLabV3Plus import DeepLabV3Plus  # The DeepLabV3+ model implementation\n",
    "from Trainer import Trainer  # The Trainer class to handle the training process\n",
    "from DisplayCallback import DisplayCallback  # The display callback for visualization\n",
    "from ModelEvaluator import ModelEvaluator\n",
    "\n",
    "IMG_SIZE = 256 # Replace with your image size\n",
    "N_CLASSES = 21  # Replace with the number of classes in your dataset\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "BASE_DIR = os.getcwd()\n",
    "DATASET_PATH = 'ADEChallengeData2016/images'\n",
    "DOWNLOAD_PATH = 'path_to_download'\n",
    "DOWNLOAD_PATH = os.path.join(BASE_DIR, DOWNLOAD_PATH)\n",
    "DATASET_PATH = os.path.join(DOWNLOAD_PATH, DATASET_PATH)\n",
    "downloader = ADE20KDownloader(DOWNLOAD_PATH)\n",
    "downloader.download_ade(overwrite=False)  # Overwrite existing files if set to True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba7cab9f-df86-4906-9db2-f4e72c619ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Training Dataset contains 20210 images.\n",
      "The Validation Dataset contains 2000 images.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 17:51:28.475005: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1 Max\n",
      "2023-11-05 17:51:28.475030: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 64.00 GB\n",
      "2023-11-05 17:51:28.475035: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 24.00 GB\n",
      "2023-11-05 17:51:28.475070: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:303] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-11-05 17:51:28.475084: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:269] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    " \n",
    "training_data = \"training/\"\n",
    "val_data = \"validation/\"\n",
    "SEED = 42\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "TRAINSET_SIZE = len(glob( os.path.join(DATASET_PATH,training_data) + \"*.jpg\"))\n",
    "print(f\"The Training Dataset contains {TRAINSET_SIZE} images.\")\n",
    "\n",
    "VALSET_SIZE = len(glob(os.path.join(DATASET_PATH,val_data)+ \"*.jpg\"))\n",
    "print(f\"The Validation Dataset contains {VALSET_SIZE} images.\")\n",
    "\n",
    "\n",
    "def parse_image(img_path: str) -> dict:\n",
    "    \"\"\"Load an image and its annotation (mask) and returning\n",
    "    a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    img_path : str\n",
    "        Image (not the mask) location.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary mapping an image and its annotation.\n",
    "    \"\"\"\n",
    "    image = tf.io.read_file(img_path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.convert_image_dtype(image, tf.uint8)\n",
    "\n",
    "    # For one Image path:\n",
    "    # .../trainset/images/training/ADE_train_00000001.jpg\n",
    "    # Its corresponding annotation path is:\n",
    "    # .../trainset/annotations/training/ADE_train_00000001.png\n",
    "    mask_path = tf.strings.regex_replace(img_path, \"images\", \"annotations\")\n",
    "    mask_path = tf.strings.regex_replace(mask_path, \"jpg\", \"png\")\n",
    "    mask = tf.io.read_file(mask_path)\n",
    "    # The masks contain a class index for each pixels\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    # In scene parsing, \"not labeled\" = 255\n",
    "    # But it will mess up with our N_CLASS = 150\n",
    "    # Since 255 means the 255th class\n",
    "    # Which doesn't exist\n",
    "    mask = tf.where(mask == 255, np.dtype('uint8').type(0), mask)\n",
    "    # Note that we have to convert the new value (0)\n",
    "    # With the same dtype than the tensor itself\n",
    "\n",
    "    return {'image': image, 'segmentation_mask': mask}\n",
    "\n",
    "\n",
    "train_dataset = tf.data.Dataset.list_files( os.path.join(DATASET_PATH, training_data) + \"*.jpg\", seed=SEED)\n",
    "train_dataset = train_dataset.map(parse_image)\n",
    "\n",
    "val_dataset = tf.data.Dataset.list_files(os.path.join(DATASET_PATH, val_data) + \"*.jpg\", seed=SEED)\n",
    "val_dataset =val_dataset.map(parse_image)\n",
    "\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def create_ade20k_label_colormap(file_path):\n",
    "    \"\"\"Creates a label colormap used in ADE20K segmentation benchmark from a file.\n",
    "\n",
    "    Args:\n",
    "      file_path: The path to the CSV file containing the colormap.\n",
    "\n",
    "    Returns:\n",
    "      A colormap for visualizing segmentation results.\n",
    "    \"\"\"\n",
    "    colormap = []\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        for row in reader:\n",
    "            colormap.append([int(c) for c in row])\n",
    "\n",
    "    return np.asarray(colormap)\n",
    "\n",
    "# Example usage:\n",
    "# Make sure to have a file 'ade20k_colormap.csv' with the color values.\n",
    "file_path = 'ade20k_colormap.csv'\n",
    "ade20k_colormap = create_ade20k_label_colormap(file_path)\n",
    "\n",
    "with open(\"objectInfo151.txt\", \"r\") as file:\n",
    "    lines = file.readlines()[1:152]\n",
    "\n",
    "class_names = []\n",
    "pixel_count_dict = {}\n",
    "color_dict = {}  # This dictionary will store the color for each class\n",
    "for idx, line in enumerate(lines):\n",
    "    parts = line.split('\\t')\n",
    "    class_idx = int(parts[0])\n",
    "    class_name = parts[4].strip()\n",
    "    class_names.append(class_name)\n",
    "\n",
    "     \n",
    "    color_dict[class_name] = ade20k_colormap[idx]\n",
    "  \n",
    "N_TOTAL_CLASSES = len(class_names)\n",
    " \n",
    "CLASSES_COLOR_DICT = color_dict  \n",
    "#name_to_index_dict = {name: index for index, name in enumerate(class_names)}\n",
    "name_to_index_dict = {name: index for index, name in enumerate(class_names, start=0)}\n",
    " \n",
    " \n",
    "@tf.function\n",
    "def normalize(input_image: tf.Tensor, input_mask: tf.Tensor) -> tuple:\n",
    "     \n",
    "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def load_image_train(datapoint: dict) -> tuple:\n",
    "     \n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        input_image = tf.image.flip_left_right(input_image)\n",
    "        input_mask = tf.image.flip_left_right(input_mask) \n",
    "        \n",
    "    input_image = tf.image.random_brightness(input_image, max_delta=0.3)  \n",
    "    input_image = tf.image.random_contrast(input_image, lower=0.8, upper=1.2)   \n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "@tf.function\n",
    "def load_image_test(datapoint: dict) -> tuple:\n",
    "   \n",
    "    input_image = tf.image.resize(datapoint['image'], (IMG_SIZE, IMG_SIZE))\n",
    "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (IMG_SIZE, IMG_SIZE))\n",
    "\n",
    "    input_image, input_mask = normalize(input_image, input_mask)\n",
    "\n",
    "    return input_image, input_mask\n",
    "\n",
    "def filter_label(image, label):\n",
    "    label = tf.where(tf.equal(label, N_TOTAL_CLASSES), tf.cast(tf.constant(0), label.dtype), label)  \n",
    "    return image, label\n",
    "\n",
    " \n",
    "BUFFER_SIZE = 1000\n",
    "\n",
    "dataset = {\"train\": train_dataset, \"val\": val_dataset}\n",
    "\n",
    "# -- Train Dataset --#\n",
    "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "dataset['train'] = dataset['train'].map(filter_label, num_parallel_calls=tf.data.experimental.AUTOTUNE)   \n",
    "dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
    "#dataset['train'] = dataset['train'].repeat()\n",
    "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
    "dataset['train'] = dataset['train'].prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "#-- Validation Dataset --#\n",
    "dataset['val'] = dataset['val'].map(load_image_test)\n",
    "dataset['val'] = dataset['val'].map(filter_label)  # 추가\n",
    "#dataset['val'] = dataset['val'].repeat()\n",
    "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
    "dataset['val'] = dataset['val'].prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4ffad65-9de9-47df-93c9-f36926bb1af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code to create and train a model...\n",
    "# model = create_model()\n",
    "# train_model(model, train_dataset, val_dataset)\n",
    "\n",
    "# Step 3: Initialize the Model\n",
    "# Set the image size and the number of classes based on your dataset\n",
    "\n",
    "deeplab = DeepLabV3Plus(image_size=IMG_SIZE, num_classes=N_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f09eeca-1cdb-4632-86ab-03371d1853c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name=None))>, 'val': <_PrefetchDataset element_spec=(TensorSpec(shape=(None, 256, 256, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 256, 256, 1), dtype=tf.float32, name=None))>}\n",
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sean/v-newtf/lib/python3.9/site-packages/keras/src/backend.py:5714: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n",
      "2023-11-05 17:51:32.477923: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    3/20210 [..............................] - ETA: 1:15:38 - loss: 2.7946 - accuracy: 0.0388"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mdeeplab\u001b[38;5;241m.\u001b[39mmodel, dataset\u001b[38;5;241m=\u001b[39mdataset, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Step 5: Start Training\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m model_history \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Optionally, visualize the results after training\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Visualization would depend on what your 'show_predictions()' function does\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# For example, if you have a test image and mask, you could do:\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# test_img, test_mask = data_loader.get_test_sample()  # Assuming this method exists\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# predicted_mask = model.predict(test_img)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# display_segmentation(test_img, test_mask, predicted_mask)  # Assuming this function exists\u001b[39;00m\n",
      "File \u001b[0;32m~/01_Work/2023/9M/tasm/final/Trainer.py:77\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset)\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# 모델 훈련\u001b[39;00m\n\u001b[0;32m---> 77\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     79\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     81\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     83\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/v-newtf/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/v-newtf/lib/python3.9/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/v-newtf/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/v-newtf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/v-newtf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/v-newtf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/v-newtf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/v-newtf/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/v-newtf/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/v-newtf/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assume train_images, train_masks, val_images, val_masks are already prepared.\n",
    "  \n",
    "trainer = Trainer(model=deeplab.model, dataset=dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Step 5: Start Training\n",
    "model_history = trainer.train()\n",
    "\n",
    "# Optionally, visualize the results after training\n",
    "# Visualization would depend on what your 'show_predictions()' function does\n",
    "# For example, if you have a test image and mask, you could do:\n",
    "# test_img, test_mask = data_loader.get_test_sample()  # Assuming this method exists\n",
    "# predicted_mask = model.predict(test_img)\n",
    "# display_segmentation(test_img, test_mask, predicted_mask)  # Assuming this function exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5549bb21-a84c-410d-b50b-5449dc171cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-05 17:51:38.379865: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sky_count: 736\n",
      "Average Sky IoU: 0.0000\n",
      "Average mIoU: 0.0000\n"
     ]
    }
   ],
   "source": [
    "model_evaluator = ModelEvaluator(deeplab.model, dataset, name_to_index_dict, CLASSES_COLOR_DICT)\n",
    "model_evaluator.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3461e4b2-b781-412c-a6c1-ff6cc913e216",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c31bb42-9914-46b5-8c77-2539c53725bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
